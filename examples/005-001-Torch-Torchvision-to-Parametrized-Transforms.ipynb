{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# 1. Original code in `torch`/`torchvision`\n",
    "#--------------------------------------------------------------------------------\n",
    "# Credits-- this example is adapted and modified from pytorch's tutorial.\n",
    "\n",
    "\n",
    "#----------------------------------------\n",
    "# Dependencies.\n",
    "#----------------------------------------\n",
    "\n",
    "import torch\n",
    "from torch.utils import data as tu_data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms.transforms as transforms\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Define the train and test transforms.\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomApply(\n",
    "            [\n",
    "                transforms.ColorJitter(\n",
    "                    brightness=0.1,\n",
    "                    contrast=0.1,\n",
    "                    saturation=0.1,\n",
    "                    hue=0.1,\n",
    "                )\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        transforms.RandomGrayscale(p=0.1),\n",
    "        transforms.RandomApply(\n",
    "            [transforms.GaussianBlur(kernel_size=3, sigma=[0.1, 2.0])], p=0.5\n",
    "        ),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Define the dataloaders.\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "# Get the train loader.\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True, transform=train_transform\n",
    ")\n",
    "trainloader = tu_data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Get the test loader.\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, download=True, transform=test_transform\n",
    ")\n",
    "testloader = tu_data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Define the model.\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Get the optimizer.\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Training phase.\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "NUM_EPOCHS = 2\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # Get the batch.\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute the loss, backprop the gradients, and update the parameters.\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print running statistics.\n",
    "        running_loss += loss.item()\n",
    "        if (i + 1) % 100 == 0:  # print every 200 mini-batches\n",
    "            print(f\"[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 200:.3f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# 2. New code in using `parameterized_transforms`\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "#----------------------------------------\n",
    "# Dependencies.\n",
    "#----------------------------------------\n",
    "\n",
    "import torch\n",
    "from torch.utils import data as tu_data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "\n",
    "# import torchvision.transforms.transforms as transforms\n",
    "import parameterized_transforms.transforms as transforms\n",
    "import parameterized_transforms.wrappers as wrappers\n",
    "import parameterized_transforms.core as core\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Define the train and test transforms.\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "train_transform = wrappers.CastParamsToTensor(\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomApply(\n",
    "                [\n",
    "                    transforms.ColorJitter(\n",
    "                        brightness=0.1,\n",
    "                        contrast=0.1,\n",
    "                        saturation=0.1,\n",
    "                        hue=0.1,\n",
    "                        default_params_mode=core.DefaultParamsMode.RANDOMIZED,  # Extra subtle detail!\n",
    "                    )\n",
    "                ],\n",
    "                p=0.5,\n",
    "            ),\n",
    "            transforms.RandomGrayscale(p=0.1),\n",
    "            transforms.RandomApply(\n",
    "                [transforms.GaussianBlur(kernel_size=3, sigma=[0.1, 2.0])], p=0.5\n",
    "            ),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "test_transform = wrappers.CastParamsToTensor(\n",
    "    transform=wrappers.ApplyDefaultParams(\n",
    "        transform=transforms.Compose(\n",
    "            [\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomApply(\n",
    "                    [\n",
    "                        transforms.ColorJitter(\n",
    "                            brightness=0.1,\n",
    "                            contrast=0.1,\n",
    "                            saturation=0.1,\n",
    "                            hue=0.1,\n",
    "                            default_params_mode=core.DefaultParamsMode.RANDOMIZED,  # Extra subtle detail!\n",
    "                        )\n",
    "                    ],\n",
    "                    p=0.5,\n",
    "                ),\n",
    "                transforms.RandomGrayscale(p=0.1),\n",
    "                transforms.RandomApply(\n",
    "                    [transforms.GaussianBlur(kernel_size=3, sigma=[0.1, 2.0])], p=0.5\n",
    "                ),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Define the dataloaders.\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "# Get the train loader.\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True, transform=train_transform\n",
    ")\n",
    "trainloader = tu_data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Get the test loader.\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, download=True, transform=test_transform\n",
    ")\n",
    "testloader = tu_data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Define the model.\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Get the optimizer.\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Training phase.\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "NUM_EPOCHS = 2\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # Get the batch.\n",
    "        (inputs, params), labels = data\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute the loss, backprop the gradients, and update the parameters.\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print running statistics.\n",
    "        running_loss += loss.item()\n",
    "        if (i + 1) % 100 == 0:  # print every 200 mini-batches\n",
    "            print(f\"[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 200:.3f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# 3. Emulating `torchvision` with `parameterized_transforms`\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Dependencies.\n",
    "import parameterized_transforms.core as ptc\n",
    "import parameterized_transforms.transforms as ptx\n",
    "import parameterized_transforms.utils as ptu\n",
    "import parameterized_transforms.wrappers as ptw\n",
    "\n",
    "import torchvision.transforms.functional as tv_fn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import PIL.Image as Image\n",
    "import PIL.ImageChops as ImageChops\n",
    "\n",
    "import typing as t\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def show_image(\n",
    "    data: Image.Image, title: str, params: t.Any = (), save: bool = False,\n",
    ") -> None:\n",
    "    \"\"\"Helper function to visualize the images.\n",
    "\n",
    "    :param data: The image data of type `PIL.Image.Image`.\n",
    "    :param title: The title of the image.\n",
    "    :param params: The parameters for the image.\n",
    "        DEFAULT: `()`.\n",
    "    :param save: Whether to save the image.\n",
    "        DEFAULT: `True`.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set figure style.\n",
    "    plt.style.use(\"dark_background\")\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "    # Process the data.\n",
    "    data = np.asarray(data).astype(np.uint8)\n",
    "    assert 0.0 <= np.min(data) <= np.max(data) <= 255.0\n",
    "\n",
    "    # Clean the parameters.\n",
    "    params = tuple(\n",
    "        (int(elt) if elt == np.floor(elt) else round(elt, 2)) for elt in params\n",
    "    )\n",
    "\n",
    "    # Plot the image.\n",
    "    plt.imshow(data)\n",
    "    plt.title(f\"{title}\\nparams = {params}\", fontdict={\"size\": 15})\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if save:\n",
    "        plt.savefig(f\"{title}.png\")\n",
    "    plt.show(block=False)\n",
    "\n",
    "\n",
    "cat_img = Image.open(\"../assets/cat.jpg\")\n",
    "width, height = cat_img.size\n",
    "print(f\"INFO | cat image dimensions: (width={width}, height={height})\")\n",
    "dog_img = Image.open(\"../assets/dog.jpg\")\n",
    "width, height = dog_img.size\n",
    "print(f\"INFO | dog image dimensions: (width={width}, height={height})\")\n",
    "# Show the images.\n",
    "show_image(data=cat_img, title=\"Original Cat Image\", params=())\n",
    "show_image(data=dog_img, title=\"Original Dog Image\", params=())\n",
    "plt.close(\"all\")\n",
    "\n",
    "\n",
    "class RandomColorErasing(ptc.AtomicTransform):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        tx_mode: ptc.TransformMode = ptc.TransformMode.CASCADE,\n",
    "        default_params_mode: ptc.DefaultParamsMode = ptc.DefaultParamsMode.RANDOMIZED,\n",
    "    ) -> None:\n",
    "        \"\"\"The initializer.\n",
    "\n",
    "        :param tx_mode: The mode of the transform.\n",
    "            DEFAULT: `ptc.TransformMode.CASCADE`.\n",
    "            SUPPORTS: `ptc.TransformMode` enum type.\n",
    "        :param default_params_mode: The mode of the default (identity) params.\n",
    "            DEFAULT: `ptc.DefaultParamsMode.RANDOMIZED`.\n",
    "            SUPPORTS: `ptc.DefaultParamsMode`.\n",
    "        \"\"\"\n",
    "\n",
    "        super(RandomColorErasing, self).__init__()\n",
    "\n",
    "        self.tx_mode = tx_mode  # Alternatively, pass tx_mode=tx_mode to the above super call.\n",
    "        self.default_params_mode = default_params_mode\n",
    "\n",
    "        self.param_count = self.set_param_count()  # Recommended.\n",
    "\n",
    "    def set_param_count(self) -> int:\n",
    "        \"\"\"Returns the number of parameters for the transform.\n",
    "\n",
    "        :return: The number of parameters.\n",
    "\n",
    "        We encode the rectangle to be erased using 4 integers `i, j, h, w`.\n",
    "        The tuple `(i, j)` encodes the top-left point of the crop\n",
    "            (along the height and the width respectively).\n",
    "        The integers `h, w` are the crop height and crop width.\n",
    "        We encode the fill-color in terms of 3 integers in range `[0, 255]`\n",
    "            representing the `R, G, B` components.\n",
    "\n",
    "        Thus, in total, there are 7 parameters.\n",
    "        \"\"\"\n",
    "        return 7\n",
    "\n",
    "    def get_raw_params(self, img: ptc.IMAGE_TYPE) -> ptc.PARAM_TYPE:\n",
    "        \"\"\"Get raw parameters to decide which rectangle to erase and what\n",
    "        should be the fill value.\n",
    "\n",
    "        :param img: The input image.\n",
    "\n",
    "        :return: The parameters for the rectangle to be erased and the fill value.\n",
    "        \"\"\"\n",
    "\n",
    "        # Get a randomly sampled fill color.\n",
    "        fill_color = np.random.randint(\n",
    "            low=0, high=256, size=[3, ]\n",
    "        ).astype(np.uint8)\n",
    "\n",
    "        # Get the image dimensions.\n",
    "        W, H = tv_fn.get_image_size(img=img)\n",
    "        # Select two heights for the crop.\n",
    "        i1, i2 = np.random.randint(low=0, high=H, size=[2, ]).tolist()\n",
    "        j1, j2 = np.random.randint(low=0, high=W, size=[2, ]).tolist()\n",
    "        # Get the location and size of the rectangle to be erased.\n",
    "        i, h = min(i1, i2), max(abs(i2 - i1), 1)\n",
    "        j, w = min(j1, j2), max(abs(j2 - j1), 1)\n",
    "\n",
    "        # Return the tuple of raw parameters.\n",
    "        return (i, j, h, w, fill_color)\n",
    "\n",
    "    def apply_transform(\n",
    "            self, img: ptc.IMAGE_TYPE, params: ptc.PARAM_TYPE, **kwargs\n",
    "    ) -> ptc.IMAGE_TYPE:\n",
    "        \"\"\"Augments given data point using given parameters.\n",
    "\n",
    "        :param img: The data point to be augmented.\n",
    "        :param params: The raw parameters to be used for augmentation.\n",
    "\n",
    "        :return: The augmented image.\n",
    "        \"\"\"\n",
    "\n",
    "        # Unpack the raw parameters.\n",
    "        i, j, h, w, fill_color = params\n",
    "\n",
    "        # Conver the `PIL` image to `numpy`.\n",
    "        img_np = np.asarray(img).astype(np.uint8)\n",
    "        # Replace the rectangular region with the sampled color.\n",
    "        img_np[i: (i + h), j: (j + w), :] = fill_color\n",
    "\n",
    "        # Convert this processed image back to a `PIL.image`\n",
    "        aug = Image.fromarray(img_np)\n",
    "\n",
    "        return aug\n",
    "\n",
    "    def post_process_params(\n",
    "        self, img: ptc.IMAGE_TYPE, params: ptc.PARAM_TYPE\n",
    "    ) -> ptc.PARAM_TYPE:\n",
    "        \"\"\"Post-processes the parameters of augmentations before outputting.\n",
    "\n",
    "        :param img: The data point to be augmented.\n",
    "        :param params: The raw local parameters to be post-processed.\n",
    "\n",
    "        :return: The post-processed parameters.\n",
    "        \"\"\"\n",
    "\n",
    "        # Unpack all parameters into a tuple of scalars.\n",
    "        i, j, h, w, fill_color = params\n",
    "        r, g, b = fill_color.tolist()\n",
    "\n",
    "        return (i, j, h, w, r, g, b)\n",
    "\n",
    "    def extract_params(\n",
    "        self, params: ptc.PARAM_TYPE\n",
    "    ) -> t.Tuple[ptc.PARAM_TYPE, ptc.PARAM_TYPE]:\n",
    "        \"\"\"Chunks the input parameters into two sets; the first required for\n",
    "        the augmentation of the current data and the second to pass on to the\n",
    "        next augmentations.\n",
    "\n",
    "        :param params: The parameters remaining from the augmentations so far.\n",
    "\n",
    "        :return: The tuple of the local and subsequent parameters.\n",
    "        \"\"\"\n",
    "\n",
    "        return params[: self.param_count], params[self.param_count :]\n",
    "\n",
    "    def pre_process_params(self, img: ptc.IMAGE_TYPE, params: ptc.PARAM_TYPE) -> ptc.PARAM_TYPE:\n",
    "        \"\"\"Pre-processes the parameters of augmentations after inputting.\n",
    "\n",
    "        :param img: The data point to be augmented.\n",
    "        :param params: The parameters from which to extract local parameters.\n",
    "\n",
    "        :return: The pre-processed parameters ready for their usage.\n",
    "        \"\"\"\n",
    "\n",
    "        # Unpack all parameters.\n",
    "        i, j, h, w, r, g, b = params\n",
    "        # Return the parameters as required for applying the transform.\n",
    "        fill_color = np.array([r, g, b]).astype(np.uint8)\n",
    "\n",
    "        # Return the raw parameters.\n",
    "        return (i, j, h, w, fill_color)\n",
    "\n",
    "    def get_default_params(self, img: ptc.IMAGE_TYPE, processed: bool = True) -> ptc.PARAM_TYPE:\n",
    "        \"\"\"Returns the parameters for preserving the input data information.\n",
    "\n",
    "        :param img: The data point to be augmented.\n",
    "        :param processed: Whether we want the processed default parameters.\n",
    "\n",
    "        :return: The no-augmentation params for the class.\n",
    "        \"\"\"\n",
    "\n",
    "        # If the default parameters are required to be unique, ...\n",
    "        if self.default_params_mode == ptc.DefaultParamsMode.UNIQUE:\n",
    "\n",
    "            # Define the rectangle to erase at the origin, with size 0.\n",
    "            i, j, h, w = 0, 0, 0, 0\n",
    "            # Define the fill color to be `(R, G, B) = (0, 0, 0)`.\n",
    "            fill_color = np.zeros([3, ]).astype(np.uint8)\n",
    "\n",
    "            raw_params = (i, j, h, w, fill_color)\n",
    "\n",
    "        # Else, ...\n",
    "        else:  # `self.default_params_mode == ptc.DefaultParamsMode.RANDOMIZED`\n",
    "\n",
    "            # Select any point of the image as the rectangle location.\n",
    "            W, H = tv_fn.get_image_size(img=img)\n",
    "            i = int(np.random.randint(low=0, high=H))\n",
    "            j = int(np.random.randint(low=0, high=W))\n",
    "            # Set the size of the rectangle to 0.\n",
    "            h, w = 0, 0\n",
    "\n",
    "            # Select any fill color.\n",
    "            fill_color = np.random.randint(\n",
    "                low=0, high=256, size=[3, ]\n",
    "            ).astype(np.uint8)\n",
    "\n",
    "            raw_params = (i, j, h, w, fill_color)\n",
    "\n",
    "        return (\n",
    "            self.post_process_params(img=img, params=raw_params)\n",
    "            if processed\n",
    "            else raw_params\n",
    "        )\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        \"\"\"Defines the string representation of the transform.\n",
    "\n",
    "        :return: The string representation of the transform.\n",
    "        \"\"\"\n",
    "        return (\n",
    "            f\"RandomColorErasing(\"\n",
    "            f\"param_count={self.param_count}, \"\n",
    "            f\"tx_mode={self.tx_mode}, \"\n",
    "            f\"default_params_mode={self.default_params_mode}\"\n",
    "            f\")\"\n",
    "        )\n",
    "\n",
    "\n",
    "class RandomSubsetApply(ptc.ComposingTransform):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        transforms: t.List[t.Callable],\n",
    "        tx_mode: ptc.TransformMode,\n",
    "    ) -> None:\n",
    "        \"\"\"The initializer.\n",
    "\n",
    "        :param transforms: The list of transforms.\n",
    "        :param tx_mode: The transform mode.\n",
    "        \"\"\"\n",
    "\n",
    "        super(RandomSubsetApply, self).__init__()\n",
    "\n",
    "        self.tx_mode = tx_mode\n",
    "        self.transforms = transforms  # All composing transforms will have a core transform set/list/tuple.\n",
    "\n",
    "        self.param_count = self.set_param_count()\n",
    "\n",
    "        # Set the start and end indices of core transform parameters.\n",
    "        self.idx_limits = [0]\n",
    "        for tx in self.transforms:\n",
    "            self.idx_limits.append(self.idx_limits[-1] + tx.param_count)\n",
    "        # Set the number of core transforms.\n",
    "        self.num_core_transforms = len(self.transforms)\n",
    "\n",
    "    def set_param_count(self) -> int:\n",
    "        \"\"\"Returns the total number of processed parameters generated by the\n",
    "        transform under consideration.\n",
    "\n",
    "        :return: The number of parameters for this transform.\n",
    "        \"\"\"\n",
    "\n",
    "        # The total number of parameters is just addition of those of the components.\n",
    "        return ptu.get_total_params_count(transforms=self.transforms)\n",
    "\n",
    "\n",
    "    def get_raw_params(self, img: ptc.IMAGE_TYPE) -> ptc.PARAM_TYPE:\n",
    "        \"\"\"Generates the raw parameters used to augment current data point.\n",
    "\n",
    "        :param img: The data point to be augmented.\n",
    "\n",
    "        :return: Current raw parameters to augment the data point.\n",
    "        \"\"\"\n",
    "\n",
    "        # Decide which transforms to apply and which to skip as 1's and 0's.\n",
    "        return tuple(\n",
    "            np.random.randint(low=0, high=2, size=[self.num_core_transforms])\n",
    "        )\n",
    "\n",
    "    def apply_cascade_transform(\n",
    "        self, img: ptc.IMAGE_TYPE, params: ptc.PARAM_TYPE, **kwargs\n",
    "    ) -> ptc.TRANSFORM_RETURN_TYPE:\n",
    "        \"\"\"Augments given data point using given parameters.\n",
    "\n",
    "        :param img: The data point to be augmented.\n",
    "        :param params: The parameters to be used for augmentation.\n",
    "\n",
    "        :return: The augmented image and corresponding augmentation parameters.\n",
    "        \"\"\"\n",
    "\n",
    "        # Collect the augmentation params from the core transforms.\n",
    "        aug_params = ()\n",
    "\n",
    "        for apply, tx in zip(params, self.transforms):\n",
    "\n",
    "            # If we have to apply the transform, apply and collect parameters.\n",
    "            if apply:\n",
    "                img, tx_params = tx(img=img, params=())\n",
    "            # Else, get default parameters and apply them on the image.\n",
    "            else:\n",
    "                tx_params = tx.get_default_params(img=img, processed=True)\n",
    "                img, rem_tx_params = tx.consume_transform(img=img, params=tx_params)\n",
    "                assert rem_tx_params == ()  # Safety check!\n",
    "\n",
    "            # Either way, collect the parameters.\n",
    "            aug_params += tx_params\n",
    "\n",
    "        # Return the final augmented image and the corresponding parameters.\n",
    "        return img, aug_params\n",
    "\n",
    "    def post_process_params(\n",
    "        self,\n",
    "        img: ptc.IMAGE_TYPE,\n",
    "        params: ptc.PARAM_TYPE,\n",
    "        aug_params: ptc.PARAM_TYPE\n",
    "    ) -> t.Tuple[ptc.PARAM_TYPE, ptc.PARAM_TYPE]:\n",
    "        \"\"\"Post-processes the parameters of augmentations before outputting.\n",
    "\n",
    "        :param img: The data point to be augmented.\n",
    "        :param params: The raw local parameters to be post-processed.\n",
    "        :param aug_params: The processed params from the composition of transforms.\n",
    "\n",
    "        :return: The post-processed parameters.\n",
    "        \"\"\"\n",
    "\n",
    "        # We ignore the local parameters describing which transforms to apply.\n",
    "        return (), aug_params\n",
    "\n",
    "    def extract_params(\n",
    "        self, params: ptc.PARAM_TYPE\n",
    "    ) -> t.Tuple[ptc.PARAM_TYPE, ptc.PARAM_TYPE]:\n",
    "        \"\"\"Chunks the input parameters into two sets; the first required for\n",
    "        the augmentation of the current data and the second to pass on to the\n",
    "        next augmentations.\n",
    "\n",
    "        :param params: The parameters remaining from the augmentations so far.\n",
    "\n",
    "        :return: The tuple of the local and subsequent parameters.\n",
    "        \"\"\"\n",
    "\n",
    "        return params[: self.param_count], params[self.param_count :]\n",
    "\n",
    "    def pre_process_params(\n",
    "        self, img: ptc.IMAGE_TYPE, params: ptc.PARAM_TYPE\n",
    "    ) -> t.Tuple[ptc.PARAM_TYPE, ptc.PARAM_TYPE]:\n",
    "        \"\"\"Pre-processes the parameters of augmentations after inputting.\n",
    "\n",
    "        :param img: The data point to be augmented.\n",
    "        :param params: The parameters from which to extract local parameters.\n",
    "\n",
    "        :return: The pre-processed parameters ready for their usage.\n",
    "        \"\"\"\n",
    "\n",
    "        # We do NOT need local params, the aug params contain all information.\n",
    "        return (), params\n",
    "\n",
    "    def apply_consume_transform(\n",
    "        self,\n",
    "        img: ptc.IMAGE_TYPE,\n",
    "        params: ptc.PARAM_TYPE,\n",
    "        aug_params: ptc.PARAM_TYPE\n",
    "    ) -> ptc.TRANSFORM_RETURN_TYPE:\n",
    "        \"\"\"Applies the transform with given parameters by consuming them.\n",
    "\n",
    "        :param img: The data point to be augmented.\n",
    "        :param params: The parameters remaining from the augmentations so far.\n",
    "        :param aug_params: The parameters from composition of transforms.\n",
    "\n",
    "        :return: The augmented image with the remaining parameters.\n",
    "        \"\"\"\n",
    "\n",
    "        # We ignore the local params and only chunk and apply aug_params.\n",
    "        for idx, tx in enumerate(self.transforms):\n",
    "\n",
    "            # Extract the parameters for the current transform.\n",
    "            tx_params = aug_params[\n",
    "                self.idx_limits[idx]:self.idx_limits[idx + 1]\n",
    "            ]\n",
    "            # Apply these params to the image.\n",
    "            img, rem_tx_params = tx.consume_transform(img=img, params=tx_params)\n",
    "            assert rem_tx_params == ()  # Safety check!\n",
    "\n",
    "        # Return the transformed image and the remaining parameters.\n",
    "        return img, ()\n",
    "\n",
    "    def get_default_params(\n",
    "        self, img: ptc.IMAGE_TYPE, processed: bool = True\n",
    "    ) -> ptc.PARAM_TYPE:\n",
    "        \"\"\"Returns the parameters for preserving the input data information.\n",
    "\n",
    "        :param img: The data point to be augmented.\n",
    "        :param processed: Whether we want the processed default parameters.\n",
    "\n",
    "        :return: The no-augmentation params for the class.\n",
    "        \"\"\"\n",
    "\n",
    "        # Get local params.\n",
    "        local_params = (0 for _ in range(self.num_core_transforms))  # No transform to apply.\n",
    "\n",
    "        # Collect the core default parameters.\n",
    "        core_default_params = ()\n",
    "\n",
    "        # Get core default parameters and keep on applying.\n",
    "        for tx in self.transforms:\n",
    "\n",
    "            # Get the default parameters of the core transform.\n",
    "            default_tx_params = tx.get_default_params(img=img, processed=processed)\n",
    "            # Append the parameters to core default parameters.\n",
    "            core_default_params += default_tx_params\n",
    "\n",
    "            # To make default parameters from the next transforms consistent, apply these default parameters too.\n",
    "            img, rem_tx_params = tx.consume_transform(img=img, params=default_tx_params)\n",
    "            assert rem_tx_params == ()  # Safety check!\n",
    "\n",
    "        return (\n",
    "            self.concat_params(\n",
    "                *(self.post_process_params(img=img, params=local_params, aug_params=core_default_params))\n",
    "            )\n",
    "            if processed\n",
    "            else local_params + core_default_params\n",
    "        )\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        \"\"\"Defines the string representation of the transform.\n",
    "\n",
    "        :return: The string representation of the transform.\n",
    "        \"\"\"\n",
    "\n",
    "        # Set the start and end strings.\n",
    "        start_string, end_string = \"RandomSubsetApply(\", \")\"\n",
    "\n",
    "        # Set the local details of the `RandomSubsetApply` transform.\n",
    "        details_string = ptu.indent(\n",
    "            data = (\n",
    "                f\"param_count={self.param_count},\\n\"\n",
    "                f\"tx_mode={self.tx_mode}, \"\n",
    "            ), indentor=\"  \", connector=\"\\n\"\n",
    "        )\n",
    "\n",
    "        # Get the cleaned string representation of the core transforms.\n",
    "        core_start_string, core_end_string = \"transforms=(\", \")\"\n",
    "\n",
    "        core_tx_strings = []\n",
    "        for tx in self.transforms:\n",
    "            core_tx_strings.append(\n",
    "                ptu.indent(data=str(tx), indentor=\"  \", connector=\"\\n\")\n",
    "            )\n",
    "        core_tx_string = ptu.indent(data=\",\\n\".join(core_tx_strings), indentor=\"  \", connector=\"\\n\")\n",
    "        core_combined_string = ptu.indent(\n",
    "            data=\"\\n\".join([core_start_string, core_tx_string, core_end_string]),\n",
    "            indentor=\"  \",\n",
    "            connector=\"\\n\"\n",
    "        )\n",
    "\n",
    "        return \"\\n\".join([start_string, details_string, core_combined_string, end_string])\n",
    "\n",
    "\n",
    "class ParamNormRandomColorErasing(RandomColorErasing):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        tx_mode: ptc.TransformMode = ptc.TransformMode.CASCADE,\n",
    "        default_params_mode: ptc.DefaultParamsMode = ptc.DefaultParamsMode.RANDOMIZED,\n",
    "    ) -> None:\n",
    "        \"\"\"The initializer.\n",
    "\n",
    "        :param tx_mode: The mode of the transform.\n",
    "            DEFAULT: `ptc.TransformMode.CASCADE`.\n",
    "            SUPPORTS: `ptc.TransformMode` enum type.\n",
    "        :param default_params_mode: The mode of the default (identity) params.\n",
    "            DEFAULT: `ptc.DefaultParamsMode.RANDOMIZED`.\n",
    "            SUPPORTS: `ptc.DefaultParamsMode`.\n",
    "        \"\"\"\n",
    "\n",
    "        super(ParamNormRandomColorErasing, self).__init__(\n",
    "            tx_mode=tx_mode, default_params_mode=default_params_mode\n",
    "        )\n",
    "\n",
    "        # # Since the number of parameters is going to remain the same, we do NOT need to explicitly re-define it.\n",
    "        # # In case the number of parameters changed, we MUST re-define it.\n",
    "        # self.param_count = self.set_param_count()  # Your implementation of `set_param_count`\n",
    "\n",
    "    def post_process_params(\n",
    "        self, img: ptc.IMAGE_TYPE, params: ptc.PARAM_TYPE\n",
    "    ) -> ptc.PARAM_TYPE:\n",
    "        \"\"\"Post-processes the parameters of augmentations before outputting.\n",
    "        Here, the post-processing normalizes the parameters.\n",
    "\n",
    "        :param img: The data point to be augmented.\n",
    "        :param params: The raw local parameters to be post-processed.\n",
    "\n",
    "        :return: The post-processed parameters.\n",
    "\n",
    "        Note that the normalization scheme provided here keeps ALL possible\n",
    "        default parameters in the range `[0, 1]`.\n",
    "        \"\"\"\n",
    "\n",
    "        # Get the processed parameters from `super`.\n",
    "        i, j, h, w, r, g, b = super(\n",
    "            ParamNormRandomColorErasing, self\n",
    "        ).post_process_params(img=img, params=params)\n",
    "\n",
    "        # Normalize the crop location and size by image size.\n",
    "        W, H = img.size\n",
    "        norm_i, norm_j, norm_h, norm_w = \\\n",
    "            i / H, j / W, h / H, w / W\n",
    "\n",
    "        # Normalize the colors.\n",
    "        norm_r, norm_g, norm_b = r / 255., g / 255., b / 255.\n",
    "\n",
    "        # Return the normalized parameters.\n",
    "        return (norm_i, norm_j, norm_h, norm_w, norm_r, norm_g, norm_b)\n",
    "\n",
    "    def pre_process_params(\n",
    "        self, img: ptc.IMAGE_TYPE, params: ptc.PARAM_TYPE\n",
    "    ) -> ptc.PARAM_TYPE:\n",
    "        \"\"\"Pre-processes the parameters of augmentations after inputting.\n",
    "        Here, the pre-processing un-normalizes the normalized parameters.\n",
    "\n",
    "        :param img: The data point to be augmented.\n",
    "        :param params: The parameters from which to extract local parameters.\n",
    "\n",
    "        :return: The pre-processed parameters ready for their usage.\n",
    "        \"\"\"\n",
    "\n",
    "        norm_i, norm_j, norm_h, norm_w, norm_r, norm_g, norm_b = params\n",
    "\n",
    "        # Get the image size.\n",
    "        W, H = img.size\n",
    "\n",
    "        # Unnormalize the crop location and size.\n",
    "        i, j, h, w = \\\n",
    "            int(round(norm_i * H)), \\\n",
    "            int(round(norm_j * W)), \\\n",
    "            int(round(norm_h * H)), \\\n",
    "            int(round(norm_w * W))\n",
    "\n",
    "        # Unnormalize the colors.\n",
    "        r, g, b = \\\n",
    "            int(round(norm_r * 255.)), \\\n",
    "            int(round(norm_g * 255.)), \\\n",
    "            int(round(norm_b * 255.))\n",
    "\n",
    "        # Return the pre-processed output of the `super`.\n",
    "        return super(\n",
    "            ParamNormRandomColorErasing, self\n",
    "        ).pre_process_params(img=img, params=(i, j, h, w, r, g, b))\n",
    "\n",
    "\n",
    "# Let us take the same example transform.\n",
    "parameterized_tx = ptx.RandomOrder(\n",
    "    transforms=[\n",
    "        # The first component is the `RandomSubsetApply` as seen in previous examples!\n",
    "        RandomSubsetApply(\n",
    "            transforms=[\n",
    "                ParamNormRandomColorErasing(\n",
    "                    tx_mode=ptc.TransformMode.CASCADE,\n",
    "                    default_params_mode=ptc.DefaultParamsMode.RANDOMIZED\n",
    "                ),\n",
    "                ptx.RandomRotation(degrees=45)\n",
    "            ],\n",
    "            tx_mode=ptc.TransformMode.CASCADE,\n",
    "        ),\n",
    "        # The second component is the random choice-- either solarize or apply color-jitter!\n",
    "        ptx.RandomChoice(\n",
    "            transforms=[\n",
    "                ptx.RandomSolarize(threshold=127, p=1.0),  # always solarize!\n",
    "                ptx.ColorJitter(\n",
    "                    brightness=0.8, contrast=0.8, saturation=0.8, hue=0.2\n",
    "                )\n",
    "            ],\n",
    "            tx_mode=ptc.TransformMode.CASCADE,\n",
    "        ),\n",
    "        # The third component is an application of two different gaussian blurs!\n",
    "        ptx.Compose(\n",
    "            transforms=[\n",
    "                ptx.GaussianBlur(kernel_size=21, sigma=[0.1, 2.0]),\n",
    "                ptx.GaussianBlur(kernel_size=21, sigma=[0.1, 5.0])\n",
    "            ]\n",
    "        )\n",
    "    ],\n",
    "    tx_mode=ptc.TransformMode.CASCADE,\n",
    "    default_params_mode=ptc.DefaultParamsMode.RANDOMIZED,\n",
    ")\n",
    "\n",
    "emulated_torchvision_tx = ptw.DropParams(parameterized_tx)\n",
    "\n",
    "# Reduce the image size for a faster output!\n",
    "# Original works too but you need to wait for a long time to see outputs! :)\n",
    "cat_img_small = cat_img.resize([int(dim / 16) for dim in cat_img.size])\n",
    "dog_img_small = dog_img.resize([int(dim / 16) for dim in dog_img.size])\n",
    "\n",
    "for idx_ in range(5):\n",
    "    aug_cat_small = emulated_torchvision_tx(cat_img_small)\n",
    "    aug_dog_small = emulated_torchvision_tx(dog_img_small)\n",
    "    assert isinstance(aug_cat_small, Image.Image)\n",
    "    assert isinstance(aug_dog_small, Image.Image)\n",
    "    show_image(data=aug_cat_small, title=f\"Emulated `TorchVision` Transform Output {idx_} on Cat\", params=(), save=False)\n",
    "    show_image(data=aug_dog_small, title=f\"Emulated `TorchVision` Transform Output {idx_} on Dog\", params=(), save=False)\n",
    "\n",
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
